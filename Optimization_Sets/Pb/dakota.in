environment
  graphics
  tabular_data ## output variable and objective function values to dakota_tabular.dat

variables
    continuous_design =  44
    initial_point =  2.359 2.005 1.205 2.292 2.094 2.621 2.472 1.959 1.631 1.106 3.82 0.425 1.604 1.203 1.316 1.444 1.391 1.352 1.566 4.463 5.822 2.576 1.916 0.795 2.174 2.125 1.982 1.984 2.221 2.148 5.509 0.349 2.483 2.075 1.754 2.073 1.764 2.098 2.351 2.086 2.27 5.406 10.823 5.217
    lower_bounds =  2.241 1.905 1.145 2.177 1.989 2.49 2.348 1.861 1.549 1.051 3.629 0.404 1.524 1.143 1.25 1.372 1.321 1.284 1.488 4.24 5.531 2.447 1.82 0.755 2.065 2.019 1.883 1.885 2.11 2.041 5.234 0.332 2.359 1.971 1.666 1.969 1.676 1.993 2.233 1.982 2.156 5.136 10.282 4.956
    upper_bounds =  2.477 2.105 1.265 2.407 2.199 2.752 2.596 2.057 1.713 1.161 4.011 0.446 1.684 1.263 1.382 1.516 1.461 1.42 1.644 4.686 6.113 2.705 2.012 0.835 2.283 2.231 2.081 2.083 2.332 2.255 5.784 0.366 2.607 2.179 1.842 2.177 1.852 2.203 2.469 2.19 2.384 5.676 11.364 5.478
    descriptors =  "DAKOTA_Sn_RC_1" "DAKOTA_Sn_RC_2" "DAKOTA_Sn_RC_3" "DAKOTA_Sn_RC_4" "DAKOTA_Sn_RC_5" "DAKOTA_Sn_RC_6" "DAKOTA_Sn_RC_7" "DAKOTA_Sn_RC_8" "DAKOTA_Sn_RC_9" "DAKOTA_Sn_EP_1" "DAKOTA_Sn_EP_2" "DAKOTA_Sn_EP_3" "DAKOTA_O_RC_1" "DAKOTA_O_RC_2" "DAKOTA_O_RC_3" "DAKOTA_O_RC_4" "DAKOTA_O_RC_5" "DAKOTA_O_RC_6" "DAKOTA_O_RC_7" "DAKOTA_O_EP_1" "DAKOTA_O_EP_2" "DAKOTA_Ti_RC_1" "DAKOTA_Ti_RC_2" "DAKOTA_Ti_RC_3" "DAKOTA_Ti_RC_4" "DAKOTA_Ti_RC_5" "DAKOTA_Ti_RC_6" "DAKOTA_Ti_RC_7" "DAKOTA_Ti_RC_8" "DAKOTA_Ti_RC_9" "DAKOTA_Ti_EP_1" "DAKOTA_Ti_EP_2" "DAKOTA_Pb_RC_1" "DAKOTA_Pb_RC_2" "DAKOTA_Pb_RC_3" "DAKOTA_Pb_RC_4" "DAKOTA_Pb_RC_5" "DAKOTA_Pb_RC_6" "DAKOTA_Pb_RC_7" "DAKOTA_Pb_RC_8" "DAKOTA_Pb_RC_9" "DAKOTA_Pb_EP_1" "DAKOTA_Pb_EP_2" "DAKOTA_Pb_EP_3"

## You should have reasonable guesses for the lower and upper bounds of the variables
## Otherwise, algorithm may converge very slowly
## For single elements, a wide range of values may be tested and algorithm should converge at a reasonable rate
## However, for binaries (hence many variables), you should use a more narrow range
## Initial estimates may be taken from previously optimized values of constituent elements

method
        moga ## Multi-Objective Genetic Algorithm
        max_iterations = 100 ## Dakota will stop if 100 generations reached (defaults)
        population_size = 500 ## 300 chromosomes in the initial generation, default = 50, larger No. needed if bad initial guesses (wide ranges of variables)
        max_function_evaluations = 50000 ## Default, max number of chromosomes tested
        initialization_type unique_random ## Default, creates first generation randomly such that each chomosome is unqiue, works best
        crossover_type ## How is crossover of parents performed to generate offspring
          multi_point_parameterized_binary = 2  ## This method works best; 2-point crossover performed
          crossover_rate = 0.4 ## Probability of crossover being performed to generate offspring; this value has been optimized (roughly)
        mutation_type offset_normal ## Select mutations based on Gaussian distribution around parent values, works slightly better than random mutation
          mutation_scale = 0.05 ## Standard deviation of mutation equal to 5% the range of the variable, works well, further optimization may be possible
          mutation_rate = 0.2  ## No. of mutations = 10% * population size * number of variables (each generation), low rate works well
        fitness_type domination_count ## Determine which designs to keep based on number of other designs which dominate it (default)
        replacement_type below_limit = 6 ## Only keep designs which are dominated by fewer than 6 other designs, default value, works well
          shrinkage_fraction = 0.30  ## Next generation must be at least 30% the size of the previous generation, small values work best here
        convergence_type metric_tracker ## Test convergence of objective functions (metric given by largest change in any objective function)
          percent_change = 1 num_generations = 10 ## Convergence acheived if less than 1% change occurs over ten consecutive generations (default)
        final_solutions = 10 ## Give 10 best solutions once run finishes, optimum value may depend on your problem, how many local minima exist
        output verbose ## Write details to log

interface
        asynchronous 
          evaluation_concurrency = 10 ## Keep this low to prevent overusage of CPU
        system
          analysis_driver = '$SCHRODINGER/run /home/szymansk/Optimization_Sets/analysis.py' ## In each work directory, run analysis.py
          parameters_file = 'params.in' ## In each work directory, write values of variables to params.in 
          results_file    = 'results.out' ## In each work directory, write values of objective functions
        work_directory directory_tag 
          named 'workdir_pp'

responses
    num_objective_functions =  17
	no_gradients ## No gradients needed for genetic algorithm
        no_hessians ## No hessians needed for genetic algorithm
    descriptors =  'Sn_elemental_log' 'Sn_FCC_lattice_constant' 'Sn_BCC_lattice_constant' 'O_elemental_log' 'O_FCC_lattice_constant' 'O_BCC_lattice_constant' 'Ti_elemental_log' 'Ti_FCC_lattice_constant' 'Ti_BCC_lattice_constant' 'Pb_elemental_log' 'Pb_FCC_lattice_constant' 'Pb_BCC_lattice_constant' 'Pb_BCC_phonon_frequency' 'PbO_RS_lattice_constant' 'PbSn_ZB_eos' 'PbTiO3_per_lattice_constant' 'PbTiO3_per_band_gap'
